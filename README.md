# DL-Audio_Classification

I have created a [Convolutional Neural Network](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53) for Audio Classification.

I have used [Jupyter notebook](https://jupyter.org/) for coding!

Follow the [notebook](https://github.com/Anuragtsl/DL-Audio_Classification/blob/main/Audio%20Classification.ipynb) for more!

# Audio Classification Dataset

For this project, we’ll use the RAVDESS dataset; this is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset, and is free to download.

This dataset has 7356 files rated by 247 individuals 10 times on emotional validity, intensity, and genuineness.

The entire dataset is 24.8GB from 24 actors, but we’ve lowered the sample rate on all the files.

***Download the [dataset](https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view) from here!!***


# Preview

![Image1](https://github.com/Anuragtsl/DL-Audio_Classification/blob/main/images/1.png)

![Image2](https://github.com/Anuragtsl/DL-Audio_Classification/blob/main/images/2.png)


#Njoy!!
